{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d10ac9",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9aba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries using pip\n",
    "# Uncomment and run these lines in your environment if the libraries are not already installed\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "\n",
    "# Import necessary libraries for data manipulation, processing, and machine learning.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from transformers import pipeline, DistilBertTokenizer, DistilBertForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Suppress specific warnings to avoid cluttering the output\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torch.utils.data.dataloader')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec2f6b",
   "metadata": {},
   "source": [
    "# Data Cleaning & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and announce if CUDA (GPU support) is available for PyTorch, which accelerates computations\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} for processing.\")\n",
    "\n",
    "# Load the dataset into a DataFrame and drop certain columns that are not needed for further analysis\n",
    "df = pd.read_csv('packages.csv')\n",
    "df = df.drop(['first_place', 'winner', 'share_image', 'slug', 'image_id'], axis=1)\n",
    "\n",
    "# Define a function to clean text data by removing HTML tags, punctuation, and trimming whitespace\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''  # Return an empty string for non-string inputs\n",
    "    text = re.sub('<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    return text\n",
    "\n",
    "# Apply the text cleaning function to specific columns in the DataFrame\n",
    "df['lede'] = df['lede'].apply(clean_text)\n",
    "df['lede']=df['lede'].str.replace('</p>', '', regex=False).str.replace('<p>', '', regex=False)\n",
    "df['headline'] = df['headline'].apply(clean_text)\n",
    "\n",
    "# Combine 'headline' and 'lede' columns into a single text column for processing\n",
    "df['combined_text'] = df[['headline', 'lede']].apply(lambda x: ' '.join(x.dropna().values.tolist()), axis=1)\n",
    "df['cleaned_text'] = df['combined_text'].fillna('')  # Replace NaNs with blank strings\n",
    "df = df[['cleaned_text']].copy()  # Retain only the cleaned text column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b057b36",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the zero-shot classification pipeline from Hugging Face transformers\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli', device=0 if device == \"cuda\" else -1)\n",
    "\n",
    "# Define a set of candidate labels for classification\n",
    "candidate_labels = [\n",
    "    \"Society and Social Issues\",\n",
    "    \"Relationships, Gender and Family\",\n",
    "    \"Pop Culture, Media and Entertainment\",\n",
    "    \"Authenticity, Lifestyle and Health\"\n",
    "]\n",
    "\n",
    "# Define a function to classify batches of text using the zero-shot classifier\n",
    "def classify_batch(texts, labels):\n",
    "    if not texts or not labels:\n",
    "        raise ValueError(\"Texts and labels must not be empty.\")\n",
    "    results = classifier(texts, candidate_labels=labels, truncation=True)\n",
    "    return results\n",
    "\n",
    "# Process the DataFrame in segments to manage memory usage and enhance performance\n",
    "segment_size = 1000  # Define segment size based on system capability\n",
    "total_segments = len(df) // segment_size + (1 if len(df) % segment_size != 0 else 0)\n",
    "\n",
    "for segment in range(total_segments):\n",
    "    start = segment * segment_size\n",
    "    end = min((segment + 1) * segment_size, len(df))\n",
    "    segment_df = df.iloc[start:end].copy()\n",
    "\n",
    "    # Classify each text and handle any exceptions\n",
    "    for i, row in segment_df.iterrows():\n",
    "        text = row['cleaned_text']\n",
    "        if pd.isna(text) or text.strip() == '':\n",
    "            segment_df.at[i, 'labels'] = np.nan\n",
    "            segment_df.at[i, 'scores'] = np.nan\n",
    "            continue\n",
    "        try:\n",
    "            result = classify_batch([text], candidate_labels)\n",
    "            segment_df.at[i, 'labels'] = result[0]['labels'][0]\n",
    "            segment_df.at[i, 'scores'] = result[0]['scores'][0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {i}: {e}\")\n",
    "            segment_df.at[i, 'labels'] = np.nan\n",
    "            segment_df.at[i, 'scores'] = np.nan\n",
    "\n",
    "        # Optional: Print progress every 100 records\n",
    "        if (i - start) % 100 == 0:\n",
    "            print(f\"Processed up to index {i}\")\n",
    "\n",
    "    # Save segment results to a CSV file and clear memory\n",
    "    interim_save_filename = f'packages_topics_segment_{segment}.csv'\n",
    "    segment_df.to_csv(interim_save_filename)\n",
    "    print(f\"Segment {segment} data saved to {interim_save_filename}\")\n",
    "    gc.collect()\n",
    "\n",
    "# Save the final DataFrame after processing\n",
    "df.to_csv('packages_topics_final.csv')\n",
    "\n",
    "# Initialize a folder path and a list to store DataFrames for merging\n",
    "folder_path = 'packages_topics_folder'\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through each file in the folder, read the CSV files, and append them to the list\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc11aec",
   "metadata": {},
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d894d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "# Function to classify text for sentiment\n",
    "\n",
    "def classify_for_sentiment(text):\n",
    "    # Tokenize and prepare input for the model\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Process the output to extract sentiment information\n",
    "    # outputs.logits contains the model's predictions\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiment = ['NEGATIVE', 'POSITIVE'][probabilities.argmax().item()]\n",
    "    score = probabilities.max().item()\n",
    "\n",
    "    return {'label': sentiment, 'score': score}\n",
    "    \n",
    "# Process each row and update DataFrame\n",
    "batch_size = 32  # You can tune this size\n",
    "total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "times = []\n",
    "start_time = time.time()\n",
    "\n",
    "for batch_number,batch_start in enumerate(list(range(0, len(df), batch_size))):\n",
    "    batch_end = batch_start + batch_size\n",
    "    batch_texts = df['cleaned_text'][batch_start:batch_end].tolist()\n",
    "\n",
    "    # Perform classification with truncated texts\n",
    "    batch_results = [classify_for_sentiment(text) for text in batch_texts]\n",
    "\n",
    "    # Update DataFrame\n",
    "    for i, result in enumerate(batch_results):\n",
    "        df.at[batch_start + i, 'sentiment'] = result['label']\n",
    "        df.at[batch_start + i, 'sentiment_score'] = result['score']\n",
    "\n",
    "    # Time estimation\n",
    "    batch_time = (time.time() - start_time) / (batch_start // batch_size + 1)\n",
    "    estimated_time_remaining = batch_time * (total_batches - (batch_start // batch_size + 1))\n",
    "    print(f\"Batch {batch_start // batch_size + 1}/{total_batches} processed. Estimated time remaining: {estimated_time_remaining/60:.2f} minutes\")\n",
    "    \n",
    "    # Save every 100 batches\n",
    "    if batch_number % 100 == 0:\n",
    "        interim_save_filename = f'packages_sentiment_batch_{batch_number}.csv'\n",
    "        df.to_csv(interim_save_filename)\n",
    "        print(f\"Interim data saved to {interim_save_filename}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total processing time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('packages_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17492156",
   "metadata": {},
   "source": [
    "## Emotion Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertForSequenceClassification.from_pretrained('nateraw/bert-base-uncased-emotion')\n",
    "\n",
    "# Encode and add special tokens to a text sequence (for BERT: [CLS] and [SEP])\n",
    "# with handling for maximum sequence length\n",
    "def encode_text(text, tokenizer, max_length=512):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_attention_mask=False,\n",
    "        return_tensors='pt'\n",
    "    )['input_ids']\n",
    "\n",
    "# Function to predict emotion with handling for maximum sequence length\n",
    "def predict_emotion(text, tokenizer, model, max_length=512):\n",
    "    # Encode text\n",
    "    input_ids = encode_text(text, tokenizer, max_length)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Apply softmax to logits to get probabilities\n",
    "    probabilities = softmax(logits, dim=1).numpy().flatten()\n",
    "\n",
    "    # Get the list of labels from the model config\n",
    "    labels = list(model.config.id2label.values())\n",
    "    \n",
    "    # Pair each label with its corresponding probability\n",
    "    emotion_probs = list(zip(labels, probabilities))\n",
    "    \n",
    "    # Get the emotion with the highest probability and its score\n",
    "    emotion, confidence = max(emotion_probs, key=lambda x: x[1])\n",
    "    \n",
    "    return emotion, confidence\n",
    "\n",
    "# Add new columns for emotion and confidence to the dataframe\n",
    "df['emotion'] = None\n",
    "df['confidence'] = None\n",
    "\n",
    "# Iterate over the dataframe and predict emotions\n",
    "for index, row in df.iterrows():\n",
    "    print(f'Processing index {index} of {len(df)}')\n",
    "    # Check if the text is not null\n",
    "    if pd.notnull(row['cleaned_text']):\n",
    "        # Get emotion and confidence\n",
    "        emotion, confidence = predict_emotion(row['cleaned_text'], tokenizer, model)\n",
    "        # Update the row with the new data\n",
    "        df.at[index, 'emotion'] = emotion\n",
    "        df.at[index, 'confidence'] = confidence\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv('packages_emotions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
